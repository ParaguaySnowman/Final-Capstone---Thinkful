{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-36d9d2f61b19>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-36d9d2f61b19>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    <center>\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<center>\n",
    "    \n",
    "## Final Capstone Project\n",
    "\n",
    "# Booking Cancellation and Booking Demand Analysis at a Major Resort Hotel\n",
    "\n",
    " ### by Parker Mortensen\n",
    " \n",
    " ##### in partial fulfillment of the requirements of the Data Science Program from Thinkful\n",
    " \n",
    " <center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "   \n",
    "# Research Question:\n",
    "\n",
    "## Can I forecast booking demand and cancellation rate within a reasonable degree of accuracy?\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## INTRODUCTION TO THE HOTEL BOOKINGS DATASET\n",
    "\n",
    "The dataset was obtained from Kaggle: https://www.kaggle.com/jessemostipak/hotel-booking-demand\n",
    "\n",
    "The original data was provided by Nuno Antonio and Ana de Almeida and is located here: https://www.sciencedirect.com/science/article/pii/S2352340918315191?via%3Dihub\n",
    "\n",
    "The exact provenance of the data is not provided, however the authors indicate that it is real world data.\n",
    "\n",
    "The data is of fulfilled and cancelled hotel bookings between July 2015 and August 2017. It includes arrival time, length of stay, number in party, country of provenance, and other customer marketing and demographic information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data column definitions:\n",
    "\n",
    "\n",
    "<b>is_canceled: Value indicating if the booking was canceled (1) or not (0)</b>\n",
    "\n",
    "    This is our target variable for the models. I chose a model to predict if bookings would cancel because I believe it would be a very valuable to know in order to plan how reservations could be accepted without worrying about overbooking, and to better forecast cash flows based on booking volume.\n",
    "    \n",
    "\n",
    "<b>lead_time: Number of days that elapsed between the entering date of the booking into the PMS and the arrival date.</b>\n",
    "\n",
    "    How long before arrival was the booking made?\n",
    "    \n",
    "<b>\n",
    "arrival_date_year: Year of arrival date\n",
    "arrival_date_month: Month of arrival date\n",
    "arrival_date_week_number: Week number of year for arrival date\n",
    "arrival_date_day_of_month: Day of arrival date</b>\n",
    "\n",
    "    For what date was the booking made?\n",
    "    \n",
    "\n",
    "<b>stays_in_weekend_nights: Number of weekend nights (Saturday or Sunday) the guest stayed or booked to stay at the hotel\n",
    "stays_in_week_nights: Number of week nights (Monday to Friday) the guest stayed or booked to stay at the hotel</b>\n",
    "\n",
    "\n",
    "    How long did the client intend to stay?\n",
    "<b>\n",
    "adults: Number of adults\n",
    "children: Number of children\n",
    "babies: Number of babies</b>\n",
    "\n",
    "    For how many people was the booking made?\n",
    "    \n",
    "<b>\n",
    "meal: Type of meal booked. Categories are presented in standard hospitality meal packages: Undefined/SC – no meal package; BB – Bed & Breakfast; HB – Half board (breakfast and one other meal – usually dinner); FB – Full board (breakfast, lunch and dinner)</b>\n",
    "\n",
    "    The meal package that the customer puchased\n",
    "\n",
    "    \n",
    "<b>country: Country of origin. Categories are represented in the ISO 3155–3:2013 format</b>\n",
    "\n",
    "    What country are they from?\n",
    "    \n",
    "\n",
    "<b>market_segment: Market segment designation. In categories, the term “TA” means “Travel Agents” and “TO” means “Tour Operators”\n",
    "distribution_channel: Booking distribution channel. The term “TA” means “Travel Agents” and “TO” means “Tour Operators”</b>\n",
    "\n",
    "    These columns refer to what industry and marketing channel the customer was sold from.\n",
    "    \n",
    "\n",
    "<b>is_repeated_guest: Value indicating if the booking name was from a repeated guest (1) or not (0)</b>\n",
    "\n",
    "    Has the customer stayed at the hotel before?\n",
    "    \n",
    "<b>\n",
    "previous_cancellations: Number of previous bookings that were cancelled by the customer prior to the current booking\n",
    "previous_bookings_not_canceled: Number of previous bookings not cancelled by the customer prior to the current booking</b>\n",
    "\n",
    "    How many previous bookings has the customer made and canceled or not canceled?\n",
    "\n",
    "<b>\n",
    "reserved_room_type: Code of room type reserved. Code is presented instead of designation for anonymity reasons.\n",
    "assigned_room_type: Code for the type of room assigned to the booking. Sometimes the assigned room type differs from the reserved room type due to hotel operation reasons (e.g. overbooking) or by customer request. Code is presented instead of designation for anonymity reasons.</b>\n",
    "\n",
    "    What kind of room did the customer book?\n",
    "\n",
    "\n",
    "<b>booking_changes: Number of changes/amendments made to the booking from the moment the booking was entered on the PMS until the moment of check-in or cancellation.</b>\n",
    "\n",
    "    How many times did the customer change the bookign?\n",
    "\n",
    "<b>\n",
    "deposit_type: Indication on if the customer made a deposit to guarantee the booking. This variable can assume three categories: No Deposit – no deposit was made; Non Refund – a deposit was made in the value of the total stay cost; Refundable – a deposit was made with a value under the total cost of stay.</b>\n",
    "\n",
    "    Did the customer make a deposit? Was it non-refundable?\n",
    "\n",
    "\n",
    "<b>agent: ID of the travel agency that made the booking</b>\n",
    "\n",
    "    Did a travel agent make the booking? Which one?\n",
    "    \n",
    "<b>\n",
    "company: ID of the company/entity that made the booking or responsible for paying the booking. ID is presented instead of designation for anonymity reasons</b>\n",
    "\n",
    "    Is the customer traveling on business? For which company?\n",
    "\n",
    "<b>\n",
    "days_in_waiting_list: Number of days the booking was in the waiting list before it was confirmed to the customer</b>\n",
    "\n",
    "    Was the booking on the waiting list? For how long?\n",
    "\n",
    "\n",
    "<b>customer_type: Type of booking, assuming one of four categories:\n",
    "\n",
    "Contract - when the booking has an allotment or other type of contract associated to it; Group – when the booking is associated to a group;\n",
    "    \n",
    "Transient – when the booking is not part of a group or contract, and is not associated to other transient booking; \n",
    "\n",
    "Transient-party – when the booking is transient, but is associated to at least other transient booking</b>\n",
    "\n",
    "    Is is a group reservation?\n",
    "<b>\n",
    "adr: Average Daily Rate as defined by dividing the sum of all lodging transactions by the total number of staying nights</b>\n",
    "\n",
    "    How much did they pay per night?\n",
    "\n",
    "</b>\n",
    "required_car_parking_spaces: Number of car parking spaces required by the customer</b>\n",
    "\n",
    "    How much parking was needed?\n",
    "\n",
    "<b>\n",
    "total_of_special_requests: Number of special requests made by the customer (e.g. twin bed or high floor)</b>\n",
    "\n",
    "    How many special request did the customer make?\n",
    "    \n",
    "<b>\n",
    "reservation_status: Reservation last status, assuming one of three categories: Canceled – booking was canceled by the customer; Check-Out – customer has checked in but already departed; No-Show – customer did not check-in and did inform the hotel of the reason why</b>\n",
    "\n",
    "    How was the booking closed?\n",
    "\n",
    "<b>\n",
    "reservation_status_date: Date at which the last status was set. This variable can be used in conjunction with the ReservationStatus to understand when was the booking canceled or when did the customer checked-out of the hotel<b>\n",
    "    \n",
    "    When was the booking canceled or fulfilled?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries and data:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import to dataframe\n",
    "df = pd.read_csv('hotel_bookings.csv')\n",
    "\n",
    "#There are two hotels in the data set.\n",
    "#For increased model accuracy and applicability, I will examine only the Resort Hotel.\n",
    "df = df[df['hotel'] == 'Resort Hotel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 40060 entries, 0 to 40059\n",
      "Data columns (total 32 columns):\n",
      "hotel                             40060 non-null object\n",
      "is_canceled                       40060 non-null int64\n",
      "lead_time                         40060 non-null int64\n",
      "arrival_date_year                 40060 non-null int64\n",
      "arrival_date_month                40060 non-null object\n",
      "arrival_date_week_number          40060 non-null int64\n",
      "arrival_date_day_of_month         40060 non-null int64\n",
      "stays_in_weekend_nights           40060 non-null int64\n",
      "stays_in_week_nights              40060 non-null int64\n",
      "adults                            40060 non-null int64\n",
      "children                          40060 non-null float64\n",
      "babies                            40060 non-null int64\n",
      "meal                              40060 non-null object\n",
      "country                           39596 non-null object\n",
      "market_segment                    40060 non-null object\n",
      "distribution_channel              40060 non-null object\n",
      "is_repeated_guest                 40060 non-null int64\n",
      "previous_cancellations            40060 non-null int64\n",
      "previous_bookings_not_canceled    40060 non-null int64\n",
      "reserved_room_type                40060 non-null object\n",
      "assigned_room_type                40060 non-null object\n",
      "booking_changes                   40060 non-null int64\n",
      "deposit_type                      40060 non-null object\n",
      "agent                             31851 non-null float64\n",
      "company                           3108 non-null float64\n",
      "days_in_waiting_list              40060 non-null int64\n",
      "customer_type                     40060 non-null object\n",
      "adr                               40060 non-null float64\n",
      "required_car_parking_spaces       40060 non-null int64\n",
      "total_of_special_requests         40060 non-null int64\n",
      "reservation_status                40060 non-null object\n",
      "reservation_status_date           40060 non-null object\n",
      "dtypes: float64(4), int64(16), object(12)\n",
      "memory usage: 8.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#See data types and column names\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## EDA: Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only columns missing data are country, agent, and company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Country\n",
    "\n",
    "For country, almost all rows are populated (39596/40060 = 98.84%), since no reasonable replacement value can be deduced from examining the data, and since so little data is missing, these rows can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: country, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "#Drop rows missing country data.\n",
    "df = df.dropna(subset=['country'])\n",
    "\n",
    "#Verify\n",
    "print(df['country'][df['country'].isna()].head(1))\n",
    "\n",
    "#Reset index for later dimensionality reduction algorithms.\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agent\n",
    "\n",
    "For agent, a missing value has meaning: the customer made the booking directly instead of via a travel agency. At (103050/119390 = 86.3%) of the data present, this column is more of a concern that country. \n",
    "\n",
    "Since there is not a more reasonable assumption to make than that it means the customer booked without an agent, I will replace the missing values with a code to indicate this.\n",
    "\n",
    "This will allow me to treat the missing values as a group.\n",
    "\n",
    "I will also add a new feature which will directly indicate whether or not the booking was made by an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 535.0\n",
      "min: 1.0\n",
      "0    False\n",
      "Name: agent, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#AGENT: fill missing values with placeholder for self-booking\n",
    "\n",
    "#Decide on placeholder value\n",
    "print('max:', df.agent.max())\n",
    "print('min:', df.agent.min())\n",
    "\n",
    "#The placeholder for self-booking will be the max value plus one: 536\n",
    "\n",
    "#Fill\n",
    "df['agent'] = df['agent'].fillna(536.0)\n",
    "\n",
    "#Verify\n",
    "print(df['agent'].isna().head(1))\n",
    "\n",
    "#New derived feature\n",
    "df['self_booked'] = df['agent'] != 536.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Company\n",
    "For company, missing data also has meaning: the customer was not travelling for business, or that the trip was not paid for by a business.\n",
    "\n",
    "With around 5% of the data missing, we could have some potentially significant consequences on the model if we don't distinguidsh between business and non-business customers\n",
    "\n",
    "As with agent, a placeholder will be used to indicate non-business bookings, which will allow us to examine them as a group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 543.0\n",
      "min: 6.0\n",
      "0    False\n",
      "Name: company, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#COMPANY: fill missing values with placeholder for no company\n",
    "print('max:', df.company.max())\n",
    "print('min:', df.company.min())\n",
    "\n",
    "#There is no company id \"1\", we can use that as our placeholder\n",
    "\n",
    "#Fill\n",
    "df['company'] = df['company'].fillna(5.0)\n",
    "\n",
    "#Verify\n",
    "print(df['company'].isna().head(1))\n",
    "\n",
    "#New derived feature\n",
    "df['on_business'] = df['company'] != 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## EDA: Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cancellation Frequency\n",
    "\n",
    "More bookings are kept than are canceled, but 28% of all bookings are canceled.\n",
    "\n",
    "A very small portion of the cancellations are no-shows, less than 1%, I will treat cancellation as binary and use the is_cancelled column only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check-Out    28519\n",
      "Canceled     10790\n",
      "No-Show        287\n",
      "Name: reservation_status, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAAD3CAYAAAA5SW6NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZwcVbn/8c+3h5A9HUS2hGVkDUsCyKIgP1kUFCIIKioXUNSL3uv14gLoKAolLkRERBQuLheUXS+yDwoIIiAogkAQxIUkkLBEAtIzyWSyTJ7fH6eGTMZMZmqmu09X1/N+vfqVTHV11bcnmafPnDp1jswM55xzja8UO4Bzzrmh8YLtnHM54QXbOedywgu2c87lhBds55zLCS/YzjmXE16wnXMuJ7xgu6YmaUtJiyW1xM7i3Eh5wXZrkDRP0tK0yL0g6ceSJsTONVRp/rf2fm1mz5jZBDPrqeE595N0n6SKpJcl/VbSXulzJ0i6N8OxWiWZpPVqldfllxdstzaHm9kEYDdgd+Dz9Tpx3gqVpEnAzcB3gdcAU4EvA8ti5nLNyQu2G5CZvQDcSijcSBot6RxJz0haKOkiSWPT514r6WZJr6StzHskldLnpkj6uaQXJc2VdFLvOSQlkq6RdLmkDuALaQv/NX322V3SIkmjJG0j6U5JL6XbrpA0Od3vMmBL4Kb0N4TP9m+xplluTDP+XdKJ/bL8TNKlkjolPS5pz0G+Tdun36urzKzHzJaa2W1mNlvSjsBFwD5pnlfS88yU9LCkDknzJSV9jnd3+ucr6Wv2SXNd3idn//d0gqQ5aea5ko4d4j+xyxkv2G5AkjYHDgX+nm76BqFA7QZsS2hNnp4+dzKwANgI2AT4AmBp0b4JeDTd/y3ApyS9rc+p3glcA0wGvgncD7y7z/P/BlxjZisAAWcBU4AdgS2ABMDMjgeeIf0NwczOXsvbuirNOQV4D/B1SW/p8/wRwNVplhuB7w3ybfor0CPpJ5IOlbRB7xNm9mfgP4D70zyT06eWAB9IzzET+E9JR6bPvTn9c3L6mvvXdXJJ44HzgUPNbCKwL/DIIJldTnnBdmtzvaROYD7wD+AMSQJOBD5tZi+bWSfwdeD96WtWAJsBW5nZCjO7x8LMYnsBG5nZmWa23MzmAD/s8zoIBe16M1tlZkuBK4FjANLzvj/dhpn93cxuN7NlZvYicC6w/1DelKQtgP2Az5lZt5k9AvwIOL7Pbvea2S1pn/dlwK7rOqaZdaTHtPR9vZi24DdZx2vuMrPH0vc7m/AhMqT3MIBVwC6SxprZ82b2+AiO5RqYF2y3NkemrbUDgGnAawkt53HAQ2m3xyvAL9PtEFrGfwduS389b0u3bwVM6X1N+rovEFrhveb3O/81hG6EKYQWpwH3AEjaWNLVkp5Nu1AuT/MNxRSg98Om19OEln+vF/r8vQsYM1i/upn92cxOMLPNgV3S85w30P6S3iDp12kXUYXQCh/qe+h/7iXA+9JjPC+pXdK04RzLNT4v2G5AZvYb4MfAOcAiYCmws5lNTh/l9OIkZtZpZieb2dbA4cBn0q6G+cDcPq+ZbGYTzeywvqfqd95XgNuA9xK6Q66y1fMAn5XuP8PMJgHHEbpJ1nqsfp4DXiNpYp9tWwLPDvmbMggze5LwPdtlHXmuJHS3bGFmZUI/t9ax/xLCh2WvTfud81YzO5jwG86ThJa+a0JesN1gzgMOBmYQCsG3JW0MIGlqb1+0pHdI2jbtwugAetLHA0CHpM9JGiupRdIuvcPe1uFKQj/vu9O/95oILCZclJsKnNrvdQuBrdd2QDObD9wHnCVpjKQZwEeAK4b0nVgLSdMknZz29/d2uxwD/K5Pns0lrd/vPbxsZt2S9iZ8KPV6kdDF0fc9PAK8WWFMeZk+o3YkbSLpiLQvexnhe1OzIYwuLi/Ybp3SfuJLgS8BnyN0e/wu7Y74FbBDuut26deLCRcNL0z7ansILe7dgLmElvqPgPIgp74xPeZCM3u0z/YvA68HKkA7cG2/150FfDHtfjllLcc9BmgltLavA84ws9sHybIuncAbgN9LWkIo1H8iXIQFuBN4HHhB0qJ028eBM9PrBKcDP+s9mJl1AV8Dfpu+hzem+X4KzAYeIgwj7FVKz/Uc8DKhL/zjI3g/roHJV5xxzrl88Ba2c87lRK7uKnMuBklbAk8M8PROZvZMPfO44vIuEeecywnvEnHOuZzwgu2ccznhBds553LCC7ZzzuWEF2znnMsJL9jOOZcTXrCdcy4nvGA751xOeMF2zrmc8ILtnHM54QXbOedywid/ck2hta19PGE5slbCKjKTgLF9HmMG+HsPYR7pl9bx50vAonmzZi6r2xtybi188ieXL0l5W8JiCNOAadf27NfzmRUfP4xhromYwSrgKcLq77PTPx+dN2vm0zU+r3Ov8oLtGldS3oCwmkvvY29gw767zFm16f0HLT93nwjpelWAx1hdyB8B/jhv1syVETO5JuUF2zWOpDyGsFL7YcAhwPasucDuv1hio5/cedkljbZKeAfwa+BW4NZ5s2bOiZzHNQkv2C6upLwFMDN9HMSaq4MPyozO1y27cuLge0b1FHATcD1w77xZM32RXDcsXrBd/SXljYFjgeOB3Ud6uL26L1j0IhvUug+7Wl4kFO/rgF9614nLwgu2q4+kPBo4Avgg8DaqOELpA8s/99jdq3adXq3j1dGzwA+BH8ybNfP52GFc4/OC7WorKe8M/DfwPmByLU5xzoqj7/1ez1H71eLYdbKS0OK+cN6smXdFzuIamBdsVxtJ+a3AycDba32qW3v2+M3HVpy8f63PUydPABcCl86bNbMzdhjXWLxgu+pJyqMILemTCWOl62LOqs3uO2j5t/at1/nqZDFwOXD+vFkz/xw7jGsMXrDdyCXl9YATgS8Am9f79A06tK9aeoCfAF+aN2vmc7HDuLi8YLvhS8oCjga+CmwXK4YZHa9bduWkWOevky7gPOAb82bN7IgdxsXhBdsNT1I+EPgGsFfsKAB7dl+4aBGT8zK0byReBL4CXDRv1swVscO4+vLZ+lw2SXkaSfkXwJ00SLEG2LH0TFGGxW0EnA880drWfnStTiJpU0lXS3pK0hOSbpG0fa3O1+e8izPun0g6pVZ5Go0XbDc0SXl9knJCmDOj5iM/stpVTxWtm2Bb4Getbe33t7a1V/WCqyQRhhneZWbbmNlOhOsTm1TzPC47L9hucEl5P0KhPgNYP3KatdqlNLeodwy+Ebinta39nNa29tFVOuaBwAozu6h3g5k9Ajws6Q5Jf5T0mKR3AkhqlfRnST+U9Lik2ySNTZ/bVtKvJD2avm6bdPupkv4gabakL68txED7SDpN0l8k/QrYoUrvORe8YLuBJeUySfn7wN2E6Uwb1nZ6dlTsDBGVCEMp/9Da1j6jCsfbBXhoLdu7gaPM7PWEov6ttDUO4aLzBWa2M/AK8O50+xXp9l2BfYHnJR2S7r83YfjnHpLe3PdEA+0jaQ/g/YQpDd5FA3XL1YMvYODWLikfTBhOtlnsKEOxif65QewMDWA68EBrW/uXgG/NmzVzVZWPL+DraXFdBUxldTfJ3LQVDqHYt0qaCEw1s+sAzKwbXi3GhwAPp/tPIBTnu/uca6B9JgLXmVlXeqwbq/weG5q3sN2akvJ6JOWzCFOD5qJYA4yne0rsDA1iNHA2cGdrW/tWwzzG48Aea9l+LOGi5x5mthuwkLB6D0Df1Xh6CI3BgabGFXCWme2WPrY1s//NsE9hh7Z5wXarJeUtgd8AbQwyD3WjkShvSOWl2DkayP7A7Na29g8O47V3AqMlndi7QdJehCXY/mFmKyQdmH49IDPrABZIOjI9xmhJ4wiNgQ9LmpBunypp434vH2ifu4GjJI1NW/CHD+P95ZYXbBck5XcSVkvJ7S3eO5ae8TsB1zQJ+HFrW/s1rW3tQ+4ysnBzxlHAwemwvseBBLgF2FPSg4TW9pNDONzxwEmSZgP3AZua2W3AlcD9kh4DriF0dfTNsNZ9zOyPwE8J/1d/Dtwz1PfVDPzGmaJLyi3AN4FPx44yUt9c8d7fXtBz5Jti52hQfwPeMW/WzL/GDuKGz1vYRZaUy0A7TVCsAaaX5vqdfwPbDvh9a1v7W2MHccPnBbuokvLWwP2ExQSawrZa0JBjxBvIZOAXrW3t/xk7iBse7xIpoqS8N2GZqv4XenJtsY15YpdlF+8UO0dOnAucMm/WTC8AOeIt7KJJykcQVvRuqmINMJ7uqbEz5MhngMtb29qLfMNR7njBLpKkfAxwLRlXJs8LifJr6Hg5do4c+TegvbWtvdFXnXcpL9hFkZSPAy4DWmJHqSUf2pfZwcBdrW3tG8YO4gbnBbsIkvIHCbeZN3WxBpihpyqxM+TQ64FbWtvaJ8QO4tbNC3azS8ofAS6mIP/WPrRv2PYGrq/ijH+uBgrxQ1xYSflE4IcU6N95ex/aNxJvAa5qbWtv+t/E8qowP8iFk5SPBC4iZ3OCjNSmenly7Aw5dxTww9a29kL9v8kLL9jNKCnvQ5iHoXD/vj60ryo+BHwrdgj3rwr3A930kvJ2wI3A2NhRYpAob0DHP2PnaAKfbm1r/2LsEG5NXrCbSVLeCPgFUITVwwfkQ/uq5iutbe0fjx3CreYFu1kk5XHAzcA2saPENkNzfGhf9Xyvta39HbFDuMALdvP4PmFoVuFNL81dHjtDExHwk9a29i1iB3FesJtDUv4ocFzsGI3Ch/ZV3WuAq1vb2n0N2Mi8YOddUt4dOD92jEayqV4ux87QhPYFvhY7RNF5wc6zsADBNYSFV11qPEt9aF9tnNra1n5Y7BBF5gU73y4Bto4dotGUxOTJdPrQvurr7c/2D8RIvGDnVVL+b8JdaW4tfGhfzbyW0J/tt69H4AU7j8LyXrNix2hkPrSvpvYDvhI7RBF5wc6bpCzgRzTpIgTVMr00x4f21VabL+hbf16w8+djwIGxQzQ6H9pXcwIuaG1r9+9zHXnBzpOkvAVwduwYebCZD+2rh+0Ja0O6OvGCnS8/AHz9vSEYz9IpsTMUxBd91Ej9eMHOi6R8NPD22DHyoiQ2KLP4ldg5CmA8PhVr3XjBzoOkPBr4RuwYebNj6Wkf2lcf72ttaz8gdogi8IKdDycBr4sdIm9maK7fPFM/5/tcI7XnBbvRJeXXAqfFjpFHM0pzVsbOUCDTgf+KHaLZecFufAngIx6GYTst8BZffX25ta1949ghmpkX7EaWlKcRxl27YdhML/kHXX2V8Rn9asoLdmP7MuCtxGGaQLcP7au/E1rb2reKHaJZDatgSypJmlTtMK6PpLwt8J7YMfKsJHvNJBb7nCL1tR5wauwQzWrIBVvSlZImSRoPPAH8RZL/w9TOZ/HfgEZsRz3zbOwMBfSR1rb2TWKHaEZZCsJOZtYBHAncAmwJHF+TVEWXlKcAH4wdoxnMKM31m2fqbwx+y3pNZCnYoySNIhTsG8xsBWC1iVV4nwZ8Up0qmF6asyJ2hoL6z9a2du82rbIsBfv7wDzCrah3S9oK6KhFqEJLyhvgI0OqZgfN94u2cUwEPhw7RLMZcsE2s/PNbKqZHWbB0/g0n7XwUXyCp6rxoX1R/XdrW7tfh6miIbc+JJ0+wFNnVimLCz4SO0AzmUD3ZrEzFNjWwOHADbGDNIssn35L+jx6gEOB1hpkKq6k/GZgu9gxmklJtuFElvjQvng+GTtAM8nSJfKtPo+vAQcAPg9udXnrugZ2lC/IG9GBrW3tW8cO0SxG0r80jvArj6uGpDwJv1GmJqaXfNa+yPz/dZVk6cN+jNXD+FqAjfCVk6vpGHxh3ZqYUXpqBT2xUxTae/Gl7aoiy5Cnd/T5+0pgoZn59JXV490hNbKDFrTEzlBwe7S2tb9u3qyZc2MHybssXSJfNbOn08ezZrZS0mU1S1YkSXlrYK/YMZrVFL00OXYGx9GxAzSDLAV7575fSFoP2KO6cQrrXbEDNLMJLN00dgbnBbsaBi3Ykj4vqROYIakjfXQCC/HxldXiBbuGSrLX+tC+6PZsbWv3Ze5GaNCCbWZnmdlE4JtmNil9TDSzDc3s83XI2NyS8ibAG2PHaHbTNP/52BmcjxYZqSzjsD8vaQNJe0t6c++jluEK4lBAsUM0u+mluS/HzuC8W2SkssyH/e/A3cCthJVQbiWsN+hGZmbsAEUwo/SUz9oX316tbe2tsUPkWZaLjp8kjGR42swOBHYHXqxJqqJIyi3AwbFjFIEP7WsYb40dIM+yFOxuM+sGkDTazJ4EdqhNrMKYjq+IXhdTtMi/z43Br9eMQJYbZxZImgxcD9wu6Z+Az9EwMm+KHaAoJvrQvkbhBXsEslx0PMrMXjGzBPgS8L/AO2sVrCD2ix2gKEqyjSbQ5QtuxLdja1u7z/c+TFkuOr56V6OZ/cbMbgQurkmq4vAWdh1N03xfkDe+ErB37BB5NZI7HVvwOx2HLylvAWwRO0aRzCjN8QV5G8MbYgfIq5Hc6fgP/E7HkfDWdZ1NL81ZHjuDA7wfe9j8Tsd49owdoGh20Hwf2tcYvIU9TFm6RG6WNB5A0nGSzk1XTnfDs2PsAEUz1RfkbRQb+7wiw5OlYP8P0CVpV+CzwNPApTVJVQzTYgcomgl0+dC+xuHdIsOQpWCvNDMjDOX7jpl9B/DhOcORlMfgCxjXXYtso/Es7YydwwHhpjGXUZaC3Snp88BxQHs6SmRUbWI1ve0Z2Xqabph28KF9jcIX8B6GLEXjfcAy4CNm9gLhG/7NmqRqft5/HcmM0hxfkLcxbB47QB4N+db0tEif2+frZ+jThy3pfjPbp7rxmpb3X0cyozRnmS/I2xC8hT0M1fy1fEwVj9XsfHRNJDtofpb5c1zteMEehmoWbKvisZrdRrEDFNVULZoUO4MDYEJrW7sPs8zIL3zFsXHsAEU10Yf2NRLvx86omgXbl7kaOi/YkbTINh7P0sWxczjAu0Uyq2bBPr6Kx2p2XrAj2l4LfGhfY/AWdkZZpld9l6S/Sar0TgAl6dX5hc3sT7WJ2GSS8nhgXOwYReZD+xqGt7AzynLF/GzgcDP7c63CFIRfcIxsRmlOtw/tawibxQ6QN1m6RBZ6sa4Kb11HNk3P+NC+xjA6doC8yfIf90FJPyWs6bisd6OZXVv1VM3Ni0VkU7XI58BpDP6zkFGWb9gkoAs4pM82A7xgZ+P/SSObSJf/Kt4YfC6ijLLcmv6hWgYpEC/YkbXINh5H95IuxoyPnaXghlywJRlwrpmdnH59CjAhXRR8qMf4MPBpQkOzBJxmZjdIugs4xcwezJA9iiEXD0mbA98lLG1lwL3AJ81sQY2yNSsv2A3gY+vd8OCDbDWuo9RCZ6lkS1SiqwV1l5Dfslsn1vIizBzq3suAd0k6y8wWZT1VWr9OA15vZhVJE8jhAIAsxeMS4Erg6PTr49JtB1c7VJPzgt0APrneDfuvscGAlWBgS6WuJSUtXVwqdS1WqbuzpbS8o/Tqo6dSKq3qLJVWdbaU6JRYUiqpq6SWLpXWWyatt1wavVyM7pFG98A4CxeaxyL5zWVrWgBDXmVwJfADQgv5tL5PpCtfXUwowC8CH0onp+trY6ATWAxgZot7/546WtKFwGTCjKT3SBpDWLhlz/T8nzGzX0u6BWgzs9mSHgauM7MzJX0FeNrMfjTUN5VVluKxkZld0ufrH0v6VLUDFYBPB9DABBpnNn5cj43fqGdV1Y5rYF3SkiWlUteSkro6S6VlHaXSss7wIbAyffR0tJSss1RicUksVqnUVVLLUpValpU0apm0/goY3SON6YGxBuOQ8jzqKOvgyguA2ZLO7rf9e8ClZvaTtNvjfODIfvs8CiwE5kq6A7jWzG7q8/x6Zra3pMOAM4C3Av8FYGbTJU0DbpO0PXA38P8kzSMU8t4FtfcDLs/4njLJUrAXSToOuCr9+hjgpepHanpLYwdw9SfQeLPx43t6xldzDPgqWNUldXWVSl2LS+ruLJW6O0ul7o5SaUX6WNnRUlrVUSpZZ6lki0vSYpVKS0ul0lJpVHdJo5ZLo1bA6JXS2FUwxmA80tjqpRxQplXszaxD0qXASaz5c7QP8K7075cR7hnp/9oeSW8H9gLeAnxb0h59+sB7B088xOrVoPYjdANjZk9Kepqw+Mg9aYa5QDtwsMIHZ6uZ/SXLe8oqS8H+MOGT7NuEXyDvS7e5bDoG38W5oSlBaYLZhAk9PRM2rv4HwZIlpdLSxaF7qLu3W6izVFpRCb8N9HSG7iF1lkosKanUpVLL0pJe7RpKPwjGrAq/EYwndDP0Gk7j5Tzgj4Tu2IFYuiLWQ+nXN5rZ6ekShw8AD0i6PT1Gku7TO1S5h9V1caAurD8QuknmALcDrwVO7HO+mskySuQZ4IgaZimKSuwAzg0m/SCYOKGnZ+ImVfwg6IGeLqlrSanUtbSkhVlfb2YvS/oZ8BFCvzWExuP7Ca3rY4F7zawH2K33dZKmAJua2R/TTbsRFhJfl7vT492ZdoVsCfzFzJZLmg+8F/gKoe/8nPRRU4MWbEmfNbOzJX2Xtcx5bWYn1SRZ8/IWtiusFmiZaDZxYk/PRHqG3Tn0LeATfb4+CbhY0qmkFx3X8ppRwDlp4e5O9/uPQc5zIXCRpMcIfdUnmFlvS/we4C1m1iXpHsJEVvcM8/0MmcJvCevYQTrczG6S9MG1PW9mP6lJsmaWlHvwi4/OnUpSqXmrtJkM2sLucyW1y8z+r+9zko5ey0vc4DoBX23DFZ13D2aUpZW3tgGTQx5E6dbg03s6Bz4veUZD6cM+FDgMmCrp/D5PTSL067js5rN66JBzRdX/5hY3iKG0sJ8DHiR01D/U53Ej8LbaRWtqc2MHcK4BDDZKw/UzlD7sR4FHJV1pZivqkKkI5sUO4FxkFZJKZ+wQeZPlxplWSWcBOwGvDn43s62rnqr5eQvbFZ13hwxDlouOlxAmQlkJHAhcShio7rKbFzuAc5F5wR6GLAV7rJndQRi7/XR6D/5BtYnV9LyF7YrOfwaGIUuXSLekEvA3SZ8gDMnZuDaxmt4CwkXcMYPt6FyTejR2gDzK0sL+FGFe35OAPQjzYa/17kc3iKTSA8yOHcO5iB6JHSCPsrSwV/aZ9NuXCxu5h4C9Y4dwLoKVwGOxQ+RRlhb2uZKelPQVSTvXLFFx1HwqRuca1JMklWWD7+b6G3LBNrMDgQMIs1z9QNJjkr5Yq2AF4AXbFZV3hwxTphnjzOwFMzufMC3hI8DpNUlVDI+zetJ054rk4dgB8mrIBVvSjpISSX8irDxzH2EOWDccSWUFfuHRFdMDsQPkVdZV068CDjGz52qUp2juJ6wx51xRLAF+HztEXg2phZ2uj/aUmX3Hi3VV3Rk7gHN1dnf626UbhiEV7HR9tA0lrV/jPEVzF1RzDW3nGt6vYgfIsyxdIk8Dv5V0I+HXGgDM7NyqpyqKpFIhKT8IvCF2FOfqxAv2CGQp2M+ljxIwsTZxCumXeMF2xfAP/IaZERlywTazLwNIGm9mSwbb3w3ZL4AzYodwrg7uJKmse9Vvt05ZhvXtI+kJ4M/p17tKurBmyYrjD4SbkZxrdjfEDpB3WW6cOY+wJNhL8OpKNG+uRahCSSqrgGtjx3CuxrqAm2KHyLusdzrO77fJRzhUx5WxAzhXYzeTVLwrdYSyFOz5kvYFTNL6kk4h7R5xI3YPYSV155rVT2MHaAZZCvZ/AP8FTCVMwL9b+rUbqXAh5urYMZyrkU7gltghmkGWUSKLgGNrmKXorgBOjR3CuRq4gaTSHTtEM8gySuRsSZMkjZJ0h6RFko6rZbhCSSqPEmbwc67ZXBE7QLPI0iVyiJl1AO8gdIlsj7cIq+3S2AGcq7KngFtjh2gWWQr2qPTPw4CrzOzlGuQpuh8Rhj851ywu9JtlqidLwb5J0pPAnsAdkjYirPztqiWpvAxcHjuGc1XSBVwcO0QzkdnQP/wkbQB0mFmPpPHARDN7oWbpiigp7wz8KXYM56rghySVj8YO0UyyXHQcRxjG9z/ppimE1rarpqTyOD6jmWsO34sdoNlk6RK5BFgO7Jt+vQD4atUTOYDvxA7g3AjdTVLxJfCqLEvB3sbMzgZWAJjZUkA1SeXagb/GDuHcCHhjrgayFOzlksYCBiBpG3zV79oIV9XPjB3DuWG6l6Rye+wQzWioazoKuIgw2f4Wkq4A7gA+W8NsRXcVfvHR5ZPP714jQx4lIukh4BDgjYSukN+lt6u7WknKRwLXxY7hXAZ3kVQOjB2iWWXpEvkdsLWZtZvZzV6s6yCpXE9Y4MC5vPDWdQ1lKdgHAvdLekrSbEmPSfKrwLX3xdgBnBuiX5FU7o4dopll6RLZam3bzezpqiZy/yop3wXsHzuGc+vQA7zeh/LVVpbpVb0wx3MS8BDZVrl3rp4u8GJde5mWCHORhB+E82PHcG4AC4HTY4coAi/Y+XEG4e5S5xrNZ0kqldghisALdl4klcXAJ2PHcK6f3wKXxQ5RFJlm63MNICm3E+Ykdy62HmCPdLUkVwfews6fTwBLYodwDjjLi3V9ecHOm6QyF/hU7Biu8B7G57upO+8Syauk/HPgXbFjuEJaBuxJUvG5burMW9j5dSI+asTF8Tkv1nF4CzvPkvIBhFkT/YPX1cstJJWZsUMUlf+g51lSuQs4O3YMVxjPAR+KHaLIvGDn3+mAT7jjaq0bOJKk8o/YQYrMC3beJZUVwLuBeZGTuOb2UZKKT/UbmRfsZpBUFgGHA52xo7im9G2Sit/N2AC8YDeLcNX+WGBV7CiuqdwOnBo7hAu8YDeTpHITcFrsGK5p/B14H0mlJ3YQF/iwvmaUlC8BTogdw+Xac8D/I6nMiR3EreYt7Ob078DPY4dwufUycIgX68bjBbsZhV9hjwFuiR3F5U4n8HaSyuOxg7h/5QW7Wa0e7ndn7CguN7qBI3z4XuPygt3Mkkr4AYT7YkdxDW8F8N707lnXoLxgN7uksoSw4MEDsaO4hrWUcBfjTbGDuHXzgl0EYb29t+DdI+5fVQgXGP16Rw54wS6KsCbkYcD1saO4hrEQ2J+kcm/sIG5ovGAXSVJZBrwHuCh2FBfdPGA/X6CtUuAAAAV4SURBVOIrX/zGmaJKyqcBX40dw0XxKHAYSeW52EFcNt7CLqqk8jXCWG1f0LdYrgb29WKdT16w+5C0qaSrJT0l6QlJt0j6qKSbq3DsA4ZyHEnrSzovzfA3STdI2nwIrztB0pRMoZLK1cAbCXNGuOa2irC01zEkla7YYdzweMFOSRJwHXCXmW1jZjsBXwA2qXOUrwMTge3NbDvCRcJr03zrcgKQrWBD7yx/ewIj/lByDeufwKEkFV+dKOe8YK92ILDCzF69IGdmjwD3ABMkXSPpSUlX9BZPSXtI+o2khyTdKmmzdPu2kn4l6VFJf5S0Td8TSdpL0sOStu63fRxhCaZPm1lPmuESwirVB0lqlfSnPvufIimR9B5C0b1C0iOSxmZ652HY3xHAGfj0rM3mMWAvksptsYO4kfOCvdouwEMDPLc78ClgJ2Br4E2SRgHfBd5jZnsAFwNfS/e/ArjAzHYF9gWe7z2QpH0JozTeaWb9J9fZFnjGzDr6bX8Q2Hmg4GZ2TbrPsWa2m5ktHezN/oukYiSVM4GZwAuZX+8ajQHfBvYmqTwVO4yrjvViB8iJB8xsAYCkR4BW4BVCkb89bXC3AM9LmghMNbPrAMysO30dwI7AD4BDzGxtF31E+EEb6vbqSyq/JCnvDFwIvK8u53TVNh84gaTiN0o1GW9hr/Y4sMcAzy3r8/cewgedgMfTFu1uZjbdzA5Jtw/kecIEO7v3bki7Uh6R9CPCxb+t0qLf1+uBJ4CVrPlvNmYI7yu7pPIySeX9wHuBRTU5h6uVy4DpXqybkxfs1e4ERks6sXeDpL2A/QfY/y/ARpL2SfcdJWnntDtjgaQj0+2j075pCK3ymcDXJR0AYGZvSwv+v5vZEuAnwLmSWtLXfwAYl+ZbCGwsaUNJo4F39MnTSbhYWT1J5f8Iv0XcUNXjulp4ETiapPKB9JqEa0JesFMW7iA6Cjg4HVL3OJAQVt5Y2/7LCXcNfkPSo8AjhP5qgOOBkyTNJsyUt2mf1y0kLJh7gaQ3rOXQnye0wv8q6W/A0cBRFqwAzgR+TxjV8WSf1/0YuGhYFx3XJaksJKkcCfwb8GzVjuuqpQf4HrA9SeWa2GFcbfmdjm7okvJ4oA04hVp1x7gs7gE+QVKZHTuIqw8v2C67pNwKnENYIMHV3/PAqSSVK2IHcfXlBdsNX1I+EDgX2C12lIKoEIbqnUtS6YwdxtWfF2w3MklZhD75LxFu3nHVVwHOA84jqbwSO4yLxwu2q56k/HZC4d53sF3dkHQQCvW3vVA78ILtaiEpHwScBhwUO0pOPQf8D3ABSeWfscO4xuEF29VOUp4GfAz4ILBB5DR5cB9huoOfp6veO7cGL9iu9pLyGMJdkx/Du0v6ewW4HPh+OnOicwPygu3qKylPB44lDAncNnKaWBYTbnz6GfALkkp35DwuJ7xgu3iS8gxC4X4365iNsEksYc0inX1GRVd4XrBdY0jKOwBHEuYlfxMwIW6gETNgNmEOmDuBO7xIu5Hygu0aT1JejzBz4gGEybf2o9oTW1WfESYE+zWhQP+apPJS3Eiu2XjBdo0vKbcQZg3cDdg1fexEn0m16qwL+BNh9fHeib8eI6n0X3jCuarygu3yKylPJiwKsTVhPcv+j82ArDMXLidcFHyesBDAfGBBnz/nAU+RVHwpNVd3XrBdcwvdK2PSx+h+f19OaC13ES4KdpFUeiIldW5QXrCdcy4nfAED55zLCS/YzjmXE16wnXMuJ7xgO+dcTnjBds65nPCC7ZxzOeEF2znncsILtnPO5YQXbOecywkv2M45lxNesJ1zLie8YDvnXE54wXbOuZzwgu2ccznhBds553LCC7ZzzuWEF2znnMuJ/w+eSE54mIUsQgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#More bookings are kept than are canceled, but 28% of all bookings are canceled!\n",
    "\n",
    "print(df.reservation_status.value_counts())\n",
    "\n",
    "#Only 291 of the reported cancellations were no-shows, 291/40060 = 0.73%\n",
    "\n",
    "#Plot\n",
    "df.reservation_status.groupby(df.reservation_status).value_counts().plot(kind='pie',labels=['Canceled','Check-Out','No-Show'])\n",
    "plt.axis('equal')\n",
    "plt.title('Reservation_Status')\n",
    "plt.show()\n",
    "\n",
    "#Drop unused column\n",
    "df = df.drop(columns=['reservation_status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lead Time\n",
    "\n",
    "The 'elbow' in the frequency of various booking lead times occurs at around 1 1/2 weeks when aggreagated by week, and at 2 days when aggregated by day. There is a pronounced bump at 7 days. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-79ca5fdb3cc8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lead_time_in_weeks'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lead_time'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcountplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lead_time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lead_time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Count of bookings by lead time in days'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "#Lead time frequencies\n",
    "df['lead_time_in_weeks'] = df['lead_time'] // 7\n",
    "\n",
    "sns.countplot(x='lead_time', data=df[df['lead_time']<=20])\n",
    "plt.title('Count of bookings by lead time in days')\n",
    "plt.show()\n",
    "\n",
    "sns.countplot(x='lead_time_in_weeks', data=df[df['lead_time_in_weeks']<=8])\n",
    "plt.title('Count of bookings by lead time in weeks')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many book with less than one week lead time? \n",
    "#How many book with more than one week lead time?\n",
    "\n",
    "print('Less than one week:', (df['lead_time'][df['lead_time']<6]).count())\n",
    "\n",
    "print('One week or more:', (df['lead_time'][df['lead_time']>=7]).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df['gt_week_lead'] = df['lead_time'] >= 7\n",
    "df.gt_week_lead.value_counts().plot(kind='pie')\n",
    "plt.title('Number of bookings with greater than one week lead time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Arrival Date\n",
    "\n",
    "Seasonal trends are shown in the plots below. Arrival date by week number is the best, but is still quite noisy.\n",
    "\n",
    "Overall, with only 2 years and 2 months of data from only one hotel, I think It would be unwise to choose the arrival date for our model.\n",
    "\n",
    "These will be dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Arrival Date data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A standardized datetime object will be needed for some analysis\n",
    "\n",
    "#import library\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numerize month\n",
    "name_to_num = {name: num for num, name in enumerate(calendar.month_name) if num}\n",
    "df['arrival_date_month'] = df['arrival_date_month'].map(name_to_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check\n",
    "print(df['arrival_date_month'].isna().unique())\n",
    "print(df['arrival_date_month'].max())\n",
    "print(df['arrival_date_month'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create column of datetime objects\n",
    "df['arrival_date'] = df.apply(lambda row: datetime.strptime(f\"{int(row.arrival_date_year)}-{int(row.arrival_date_month)}-{int(row.arrival_date_day_of_month)}\", '%Y-%m-%d').date(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#booking counts by year\n",
    "print(df.arrival_date_year.value_counts(), '\\n')\n",
    "\n",
    "#check for partial years\n",
    "print(\"First recorded date is:\", df.arrival_date.max())\n",
    "print(\"Last recorded date is:\", df.arrival_date.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for countplots, import seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "#We need to adjust the data to not count July and August and extra time compared to the other months\n",
    "#(because of 2 years + 2 months data)\n",
    "date1 = date(2015,9,1)\n",
    "date2 = date(2017,7,1)\n",
    "\n",
    "#Two ways to cut our years\n",
    "wo_first_two = pd.DataFrame(df[df['arrival_date'] >= date1])\n",
    "wo_last_two = pd.DataFrame(df[df['arrival_date'] < date2])\n",
    "\n",
    "#Without first two months\n",
    "sns.countplot(y='arrival_date_month', data=wo_first_two)\n",
    "plt.title('Count of bookings by arrival date month')\n",
    "plt.show()\n",
    "\n",
    "#Without last two months\n",
    "sns.countplot(y='arrival_date_month', data=wo_last_two)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "#### Week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Arrival Date by Week\n",
    "\n",
    "#Create a string to set the order of rows in plot:\n",
    "week_order = np.arange(1,53)\n",
    "   \n",
    "#cast to string to permit ordering\n",
    "df.arrival_date_week_number = df.arrival_date_week_number.astype(str)\n",
    "\n",
    "#plot\n",
    "plt.figure(figsize=(16,6))\n",
    "sns.countplot(x='arrival_date_week_number', data=wo_first_two, order=week_order)\n",
    "plt.title('Count of bookings by arrival date week')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "sns.countplot(x='arrival_date_week_number', data=wo_last_two, order=week_order)\n",
    "plt.show()\n",
    "\n",
    "#There is a discernible trend in bookings by week, but the data is quite variable, leading to\n",
    "#a lower correlation. I don't think arrival date will be a very good metric for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Day of Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arrival Date by day of month\n",
    "\n",
    "df.arrival_date_day_of_month.value_counts()\n",
    "\n",
    "#There does not seem to be a discernbilbe pattern here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of Stay\n",
    "\n",
    "The most comman length of stay is two to four days. One-day and week-long stays are also very popular. The median length of stay is 4 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Length of Stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get total length of stay\n",
    "df['length_of_stay'] = df.stays_in_weekend_nights + df.stays_in_week_nights\n",
    "\n",
    "df.length_of_stay.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='length_of_stay', data=df[df['length_of_stay'] <= 14])\n",
    "plt.title('Count of Bookings by Total Length of Stay in Days')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weekends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='stays_in_weekend_nights', data=df)\n",
    "plt.title('Count of Bookings by Length of Stay in Weekend Nights')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weekdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='stays_in_week_nights', data=df[df['stays_in_week_nights']<12])\n",
    "plt.title('Count of Bookings by Length of Stay in Weeknights')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Party Size\n",
    "\n",
    "The majority of bookings were for two adults, with samller numbers of 1, 3, and 4 person parties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total number in party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['party_size'] = df.adults + df.children + df.babies\n",
    "\n",
    "sns.countplot(x='party_size', data=df[df['party_size']<6])\n",
    "plt.title('Count of Bookings by Party Size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meal\n",
    "\n",
    "By far, the most popular meal package is Bed and Breakfast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There is a problem with meal in that 'SC' and 'Undefined' both mean the same thing: no meals.\n",
    "\n",
    "df.meal.unique()\n",
    "\n",
    "meal_df = pd.DataFrame(df['meal'])\n",
    "meal_df = meal_df.replace('Undefined','SC')\n",
    "df.meal = meal_df.meal\n",
    "\n",
    "df.meal.unique()\n",
    "\n",
    "#As above, meal is categorical, we will make it numerical\n",
    "\n",
    "meal_df = pd.DataFrame(df[['is_canceled','meal']].groupby('meal', as_index=False).agg('mean'))\n",
    "meal_df = meal_df.rename(index=str, columns={\"is_canceled\": \"meal_score\"})\n",
    "df = pd.merge(df,meal_df,how='left',on=['meal'])\n",
    "\n",
    "print(df.meal.value_counts())\n",
    "\n",
    "df.meal.value_counts().plot(kind='pie')\n",
    "plt.axis('equal')\n",
    "plt.title('Meal Package')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country\n",
    "\n",
    "The most frequent countries of origin in this dataset were Portugaal (44.5%), Great Britain (17.1%), Spain (9.9%), Ireland (5.4%), France (4%), and Germany (3%), all other countries composted the remaining 16.1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.country.value_counts().head(10))\n",
    "\n",
    "major_countries = ['PRT','GBR','ESP','IRL','FRA','DEU']\n",
    "\n",
    "df['adj_country'] = df['country']\n",
    "df['adj_country'] = df['adj_country'].where(df['adj_country'].isin(major_countries), 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.adj_country.value_counts().plot(kind='pie')\n",
    "plt.axis('equal')\n",
    "plt.title('Country')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Market Segment\n",
    "\n",
    "Business at this hotel is mostly associated with Travel Agents, 44% of the bookings came from online travel agents and 18.6% came from offline travel agents and tour operators. Direct mailing, group marketing, and corporate marketing composed significant portions as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(df.market_segment.value_counts())\n",
    "\n",
    "df.market_segment.value_counts().plot(kind='pie')\n",
    "plt.axis('equal')\n",
    "plt.title('Market Segment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returning Customers\n",
    "\n",
    "In an apparent deviation from the pareto principle, it seems the majority of customers at a resort are first time customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.is_repeated_guest.value_counts())\n",
    "\n",
    "df.is_repeated_guest.value_counts().plot(kind='pie', labels=['First Time','Returning'])\n",
    "plt.axis('equal')\n",
    "plt.title('Returning Customers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reserved and Assigned Room Types\n",
    "\n",
    "The meaning of this data was retained to protect customer privacy. But large difference can be noted in the A and D types before and after final assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.reserved_room_type.value_counts())\n",
    "\n",
    "df.reserved_room_type.value_counts().plot(kind='pie')\n",
    "plt.axis('equal')\n",
    "plt.title('Reseved Room Type')\n",
    "plt.show()\n",
    "\n",
    "print(df.assigned_room_type.value_counts())\n",
    "\n",
    "df.assigned_room_type.value_counts().plot(kind='pie')\n",
    "plt.axis('equal')\n",
    "plt.title('Assigned Room Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Booking Changes\n",
    "\n",
    "Booking changes are not made frequently, 79.7% of bookings are not changed at all. 13.5% of bookings are changed once, 3.8% are changed twice, 1.1% are changed three times, 1.9% of bookings are changed more than three times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='booking_changes', data=df[df['booking_changes']<7])\n",
    "plt.title('Count of Bookings by number of booking changes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Deposit Type\n",
    "\n",
    "Most bookings do not have a deposit. The few bookings that do have a deposit are almost exclusively non-refundable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(df.deposit_type.value_counts())\n",
    "\n",
    "df.deposit_type.value_counts().plot(kind='pie')\n",
    "plt.axis('equal')\n",
    "plt.title('Deposit Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent\n",
    "\n",
    "80% of bookings were made through a travel agent or tour operator. Of those bookings, 43.7% came from one agent, #240. The top five agents accounted for 64% of bookings made by agent, and 51% of bookings overall. \n",
    "\n",
    "However, we must distinguish between bookings made and booings completed. As will be shown later, the average agent cancels 37% of the time.\n",
    "\n",
    "From the graphs below, we can infer that bookings made through an agents are, overall, somewaht less likely to be cancelled.\n",
    "\n",
    "An agent cancellation rate metric will be elaborated later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.agent.value_counts().head(10))\n",
    "print(df.self_booked.value_counts())\n",
    "\n",
    "df.self_booked.value_counts().plot(kind='pie',labels=['Booking without Agent','Bookig with Agent'])\n",
    "plt.axis('equal')\n",
    "plt.title('Method of Booking, (all bookings)')\n",
    "plt.show()\n",
    "\n",
    "df['self_booked'][df['is_canceled']==0].value_counts().plot(kind='pie',labels=['Booking without Agent','Bookig with Agent'])\n",
    "plt.axis('equal')\n",
    "plt.title('Method of Booking, (bookings not canceled)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.company.value_counts().head(11))\n",
    "\n",
    "df.on_business.value_counts().plot(kind='pie',labels=['Other/Pleasure','Business'])\n",
    "plt.axis('equal')\n",
    "plt.title('Purpose of Travel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waiting List\n",
    "\n",
    "The waiting list is seldom used, only 1.15% of bookings are ever on the wait list.\n",
    "\n",
    "They occur most frequently at week 53 (New Year), week 42 and 43, (October Break?), week 47 (Thanksgiving), week 26 (beginning of summer vacation?) and 17 (Spring Break?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['arrival_date_week_number'][df['days_in_waiting_list'] > 0].value_counts().head(6)\n",
    "\n",
    "df['was_on_waiting_list'] = df['days_in_waiting_list'] > 0\n",
    "\n",
    "df.was_on_waiting_list.value_counts().plot(kind='pie')\n",
    "plt.axis('equal')\n",
    "plt.title('Count of bookings ever on the waiting list')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer Type\n",
    "\n",
    "Most bookings (74.5%) are stand-alone parties, 19.4% were stand-alone booking associated with other group bookings, smaller portions of bookings were associated with groups or other contracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.customer_type.value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.customer_type.value_counts().plot(kind='pie')\n",
    "plt.axis('equal')\n",
    "plt.title('Customer Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Daily Rate (ADR)\n",
    "\n",
    "The denomination is not given, but I think we should assume euros, it seems cheap for dollars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['adr'][df['adr']<300])\n",
    "plt.title('Distribution of bookings by Average Daily Rate in Dollars')\n",
    "plt.xlabel('Average Daily Rate in Dollars')\n",
    "plt.ylabel('Count of Bookings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Car Parking Spaces\n",
    "\n",
    "Booking with more than one required car parking space are exceedinly rare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.required_car_parking_spaces.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special Requests\n",
    "\n",
    "One special request is common, more than 3 is rare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='total_of_special_requests', data=df[df['total_of_special_requests']<6])\n",
    "plt.title('Count of Bookings by Number of Special Requests Made')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Time Series Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Prep for Time Series Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "My goal is to create a forecast for net booking demand. To that end, I will examine total (gross) bookings (canceled and not canceled); net bookings (not canceled only); and the cancellation rate.\n",
    "\n",
    "I also need to change the format of the date information to make it compatible with the ARIMA model.\n",
    "\n",
    "Finally, as I will be modelling several time series features, I will create some altered dataframes to facilitate that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Cancellation Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#I need to calculate a cancellation frequency by date for the time series analysis\n",
    "wcr_df = pd.DataFrame(df[['is_canceled','arrival_date_year','arrival_date_week_number',]].groupby(['arrival_date_year','arrival_date_week_number'], as_index=False).agg('mean'))\n",
    "wcr_df = wcr_df.rename(index=str, columns={\"is_canceled\": \"wcr\"})\n",
    "df = pd.merge(df,wcr_df,how='left',on=['arrival_date_year','arrival_date_week_number'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gross Bookings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['c'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.DataFrame(df[['c','arrival_date_year','arrival_date_week_number']].groupby(['arrival_date_year','arrival_date_week_number'], as_index=False).agg('sum'))\n",
    "raw_df = raw_df.rename(index=str, columns={'c': \"raw_bookings\"})\n",
    "df = pd.merge(df,raw_df,how='left',on=['arrival_date_year','arrival_date_week_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.raw_bookings = df.raw_bookings.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Net Bookings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['d'] = df['is_canceled'] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_df = pd.DataFrame(df[['d','arrival_date_year','arrival_date_week_number']].groupby(['arrival_date_year','arrival_date_week_number'], as_index=False).agg('sum'))\n",
    "net_df = net_df.rename(index=str, columns={'d': \"net_bookings\"})\n",
    "df = pd.merge(df,net_df,how='left',on=['arrival_date_year','arrival_date_week_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.net_bookings = df.net_bookings.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formatting the dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['w_date'] = df.arrival_date_year.astype(str) + ' ' + df.arrival_date_week_number.astype(str) \n",
    "df['w_date'] = df['w_date'].apply(lambda x: datetime.strptime(x + ' 0', \"%Y %W %w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframes to facilitate ARIMA modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_feat_df = df[['w_date','wcr','raw_bookings','net_bookings']]\n",
    "arima_feat_df = arima_feat_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_train_df = arima_feat_df[arima_feat_df['w_date'] <= '2017-05-31']\n",
    "arima_test_df = arima_feat_df[arima_feat_df['w_date'] > '2017-05-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Finding the ordering parameters for ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The data is already pretty close to static, a difference of 1 goes negative very quickly and may be over-differenced. However, I know from examining the data that there is a slight upward trend year over year. A difference of 1 will be used as the most conservative guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "x_acf = pd.DataFrame(pacf(arima_train_df.raw_bookings))\n",
    "x_acf.plot(kind='bar')\n",
    "plt.title(\"Raw Bookings PACF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_train_df['raw_diff_1'] = arima_train_df.raw_bookings - arima_train_df.raw_bookings.shift()\n",
    "arima_train_df.plot(y='raw_diff_1')\n",
    "plt.title('Raw Bookings Time Series')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "x_acf = pd.DataFrame(pacf(arima_train_df.raw_diff_1[1:]))\n",
    "x_acf.plot(kind='bar')\n",
    "plt.title(\"Raw Bookings PACF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### AR and MA Order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Since I have selected a difference order of 1, and the differenced series dispalys a sharp cutoff with a lag-1 autocorrelation that is negative, I will add an MA order of 1 to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA models\n",
    "\n",
    "I tried various parameter configuration for the Gross Bookings model, but all of them produced underwhelming results. Trend lines did not track actual data. However, the models may be of use in a big picture or \"macro\" kind of way. The best results are discussed in each section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gross Bookings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The model with my intial ordering guess (the 0,1,1 order) did better than 0,1,0 or 1,0,0. 1,1,1 performed on a similar level to 0,1,1. So I decided to try 1,1,2 to keep the benefits (if any) from the AR term and conserve the difference between the AR and MA.\n",
    "\n",
    "(1,1,2) Did marginally better than the two previous best performers, with a smaller log likelihood, and the only p-value of the set that was greateer than 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA as ARIMA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_rb_train_df = arima_train_df[['w_date','raw_bookings']]\n",
    "arima_rb_train_df = arima_train_df.set_index('w_date')\n",
    "\n",
    "arima_rb_test_df = arima_test_df[['w_date','raw_bookings']]\n",
    "arima_rb_test_df = arima_test_df.set_index('w_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Order: 0, 1, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rb_model = ARIMA2(arima_rb_train_df.raw_bookings, order=(0,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "rb_model_fit = rb_model.fit()\n",
    "print(rb_model_fit.summary())\n",
    "print('Residuals Description')\n",
    "print(rb_model_fit.resid.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc, se, conf = rb_model_fit.forecast(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_rb_test_df['fc'] = fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_rb_test_df['l_conf'] = conf[:,0]\n",
    "arima_rb_test_df['u_conf'] = conf[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_rb_train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Forecast\n",
    "fc, se, conf = rb_model_fit.forecast(14, alpha=0.05)  # 95% conf\n",
    "# Make as pandas series\n",
    "fc_series = pd.Series(fc, index=arima_rb_test_df.index)\n",
    "lower_series = pd.Series(conf[:, 0], index=arima_rb_test_df.index)\n",
    "upper_series = pd.Series(conf[:, 1], index=arima_rb_test_df.index)\n",
    "# Plot\n",
    "plt.figure(figsize=(12,5), dpi=100)\n",
    "plt.plot(arima_rb_train_df.raw_bookings, label='training')\n",
    "plt.plot(arima_rb_test_df.raw_bookings, label='actual')\n",
    "plt.plot(fc_series, label='forecast')\n",
    "plt.fill_between(lower_series.index, lower_series, upper_series, \n",
    "                 color='k', alpha=.15)\n",
    "plt.title('Gross Bookings: Forecast vs Actuals: order(0,1,1)')\n",
    "plt.legend(loc='upper left', fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order: 1,0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rb_model = ARIMA2(arima_rb_train_df.raw_bookings, order=(1,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_model_fit = rb_model.fit()\n",
    "print(rb_model_fit.summary())\n",
    "print('Residuals Description')\n",
    "print(rb_model_fit.resid.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc, se, conf = rb_model_fit.forecast(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_rb_test_df['fc'] = fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_rb_test_df['l_conf'] = conf[:,0]\n",
    "arima_rb_test_df['u_conf'] = conf[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_rb_train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast\n",
    "fc, se, conf = rb_model_fit.forecast(14, alpha=0.05)  # 95% conf\n",
    "# Make as pandas series\n",
    "fc_series = pd.Series(fc, index=arima_rb_test_df.index)\n",
    "lower_series = pd.Series(conf[:, 0], index=arima_rb_test_df.index)\n",
    "upper_series = pd.Series(conf[:, 1], index=arima_rb_test_df.index)\n",
    "# Plot\n",
    "plt.figure(figsize=(12,5), dpi=100)\n",
    "plt.plot(arima_rb_train_df.raw_bookings, label='training')\n",
    "plt.plot(arima_rb_test_df.raw_bookings, label='actual')\n",
    "plt.plot(fc_series, label='forecast')\n",
    "plt.fill_between(lower_series.index, lower_series, upper_series, \n",
    "                 color='k', alpha=.15)\n",
    "plt.title('Gross Bookings: Forecast vs Actuals: order(1,0,0)')\n",
    "plt.legend(loc='upper left', fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order: 1,0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rb_model = ARIMA2(arima_rb_train_df.raw_bookings, order=(1,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_model_fit = rb_model.fit()\n",
    "print(rb_model_fit.summary())\n",
    "print('Residuals Description')\n",
    "print(rb_model_fit.resid.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc, se, conf = rb_model_fit.forecast(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_rb_test_df['fc'] = fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_rb_test_df['l_conf'] = conf[:,0]\n",
    "arima_rb_test_df['u_conf'] = conf[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_rb_train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast\n",
    "fc, se, conf = rb_model_fit.forecast(14, alpha=0.05)  # 95% conf\n",
    "# Make as pandas series\n",
    "fc_series = pd.Series(fc, index=arima_rb_test_df.index)\n",
    "lower_series = pd.Series(conf[:, 0], index=arima_rb_test_df.index)\n",
    "upper_series = pd.Series(conf[:, 1], index=arima_rb_test_df.index)\n",
    "# Plot\n",
    "plt.figure(figsize=(12,5), dpi=100)\n",
    "plt.plot(arima_rb_train_df.raw_bookings, label='training')\n",
    "plt.plot(arima_rb_test_df.raw_bookings, label='actual')\n",
    "plt.plot(fc_series, label='forecast')\n",
    "plt.fill_between(lower_series.index, lower_series, upper_series, \n",
    "                 color='k', alpha=.15)\n",
    "plt.title('Gross Bookings: Forecast vs Actuals: order(1,0,1)')\n",
    "plt.legend(loc='upper left', fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order: 1,1,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rb_model = ARIMA2(arima_rb_train_df.raw_bookings, order=(1,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_model_fit = rb_model.fit()\n",
    "print(rb_model_fit.summary())\n",
    "print('Residuals Description')\n",
    "print(rb_model_fit.resid.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc, se, conf = rb_model_fit.forecast(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_rb_test_df['fc'] = fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_rb_test_df['l_conf'] = conf[:,0]\n",
    "arima_rb_test_df['u_conf'] = conf[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_rb_train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast\n",
    "fc, se, conf = rb_model_fit.forecast(14, alpha=0.05)  # 95% conf\n",
    "# Make as pandas series\n",
    "fc_series = pd.Series(fc, index=arima_rb_test_df.index)\n",
    "lower_series = pd.Series(conf[:, 0], index=arima_rb_test_df.index)\n",
    "upper_series = pd.Series(conf[:, 1], index=arima_rb_test_df.index)\n",
    "# Plot\n",
    "plt.figure(figsize=(12,5), dpi=100)\n",
    "plt.plot(arima_rb_train_df.raw_bookings, label='training')\n",
    "plt.plot(arima_rb_test_df.raw_bookings, label='actual')\n",
    "plt.plot(fc_series, label='forecast')\n",
    "plt.fill_between(lower_series.index, lower_series, upper_series, \n",
    "                 color='k', alpha=.15)\n",
    "plt.title('Gross Bookings: Forecast vs Actuals: order(1,1,1)')\n",
    "plt.legend(loc='upper left', fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Order: 1,1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "rb_model = ARIMA2(arima_rb_train_df.raw_bookings, order=(1,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "rb_model_fit = rb_model.fit()\n",
    "print(rb_model_fit.summary())\n",
    "print('Residuals Description')\n",
    "print(rb_model_fit.resid.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc, se, conf = rb_model_fit.forecast(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_rb_test_df['fc'] = fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_rb_test_df['l_conf'] = conf[:,0]\n",
    "arima_rb_test_df['u_conf'] = conf[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_rb_train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Forecast\n",
    "fc, se, conf = rb_model_fit.forecast(14, alpha=0.05)  # 95% conf\n",
    "# Make as pandas series\n",
    "fc_series = pd.Series(fc, index=arima_rb_test_df.index)\n",
    "lower_series = pd.Series(conf[:, 0], index=arima_rb_test_df.index)\n",
    "upper_series = pd.Series(conf[:, 1], index=arima_rb_test_df.index)\n",
    "# Plot\n",
    "plt.figure(figsize=(12,5), dpi=100)\n",
    "plt.plot(arima_rb_train_df.raw_bookings, label='training')\n",
    "plt.plot(arima_rb_test_df.raw_bookings, label='actual')\n",
    "plt.plot(fc_series, label='forecast')\n",
    "plt.fill_between(lower_series.index, lower_series, upper_series, \n",
    "                 color='k', alpha=.15)\n",
    "plt.title('Gross Bookings: Forecast vs Actuals: order(1,1,2)')\n",
    "plt.legend(loc='upper left', fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Net Bookings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1,1,2) ordering was also the best performer for net booking forecasting, with the smallest log likelihood and a p value that approached significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA as ARIMA3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_nb_train_df = arima_train_df[['w_date','net_bookings']]\n",
    "arima_nb_train_df = arima_train_df.set_index('w_date')\n",
    "\n",
    "arima_nb_test_df = arima_test_df[['w_date','net_bookings']]\n",
    "arima_nb_test_df = arima_test_df.set_index('w_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = ARIMA3(arima_nb_train_df.net_bookings, order=(1,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model_fit = nb_model.fit()\n",
    "print(nb_model_fit.summary())\n",
    "print('Residuals Description')\n",
    "print(nb_model_fit.resid.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc, se, conf = nb_model_fit.forecast(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_nb_test_df['fc'] = fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_nb_test_df['l_conf'] = conf[:,0]\n",
    "arima_nb_test_df['u_conf'] = conf[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_nb_train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Forecast\n",
    "fc, se, conf = nb_model_fit.forecast(14, alpha=0.05)  # 95% conf\n",
    "# Make as pandas series\n",
    "fc_series = pd.Series(fc, index=arima_nb_test_df.index)\n",
    "lower_series = pd.Series(conf[:, 0], index=arima_nb_test_df.index)\n",
    "upper_series = pd.Series(conf[:, 1], index=arima_nb_test_df.index)\n",
    "# Plot\n",
    "plt.figure(figsize=(12,5), dpi=100)\n",
    "plt.plot(arima_nb_train_df.net_bookings, label='training')\n",
    "plt.plot(arima_nb_test_df.net_bookings, label='actual')\n",
    "plt.plot(fc_series, label='forecast')\n",
    "plt.fill_between(lower_series.index, lower_series, upper_series, \n",
    "                 color='k', alpha=.15)\n",
    "plt.title('Forecast vs Actuals')\n",
    "plt.legend(loc='upper left', fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Weekly Cancel Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "TSA predicated a very nearly constant cancellation rate of 30%. A simple mean cancellation incidence as measured in the Exploratory Data Analysis is 28%. If we take the slope of 0.06 and extrapolate it back over 100 observations, then we would move 6% down to 24%. Since our observed mean cancellation rate was 28%, the models output makes sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weekly Cancellation rates are a much different beast than raw bookings or net bookings. They require a separate evaulation of model ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_wcr_train_df = arima_train_df[['w_date','wcr']]\n",
    "arima_wcr_train_df = arima_train_df.set_index('w_date')\n",
    "\n",
    "arima_wcr_test_df = arima_test_df[['w_date','wcr']]\n",
    "arima_wcr_test_df = arima_test_df.set_index('w_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference, AR, and MA order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One would expect weekly cancellation rate to be static, and the plots show it is . . . on average, however I found that cancellation rates have a seasonal trend, spiking in July. So a difference of 1 was needed to make the best performing model. I found that the best terms for AR and MA were 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "x_acf = pd.DataFrame(pacf(arima_wcr_train_df.wcr))\n",
    "x_acf.plot(kind='bar')\n",
    "plt.title(\"Weekly Cancellation Rate PACF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_wcr_train_df['wcr_diff_1'] = arima_wcr_train_df.wcr - arima_wcr_train_df.wcr.shift()\n",
    "arima_wcr_train_df.plot(y='wcr_diff_1')\n",
    "plt.title('Weekly Cancellation Rate Time Series')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "x_acf = pd.DataFrame(pacf(arima_wcr_train_df.wcr_diff_1[1:]))\n",
    "x_acf.plot(kind='bar')\n",
    "plt.title(\"Weekly Cancellation Rate PACF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcr_model = ARIMA(arima_wcr_train_df.wcr, order=(0,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "wcr_model_fit = wcr_model.fit()\n",
    "print(wcr_model_fit.summary())\n",
    "print('Residuals Description')\n",
    "print(wcr_model_fit.resid.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc, se, conf = wcr_model_fit.forecast(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_wcr_test_df['fc'] = fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_wcr_test_df['l_conf'] = conf[:,0]\n",
    "arima_wcr_test_df['u_conf'] = conf[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_wcr_train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Forecast\n",
    "fc, se, conf = wcr_model_fit.forecast(14, alpha=0.05)  # 95% conf\n",
    "# Make as pandas series\n",
    "fc_series = pd.Series(fc, index=arima_wcr_test_df.index)\n",
    "lower_series = pd.Series(conf[:, 0], index=arima_wcr_test_df.index)\n",
    "upper_series = pd.Series(conf[:, 1], index=arima_wcr_test_df.index)\n",
    "# Plot\n",
    "plt.figure(figsize=(12,5), dpi=100)\n",
    "plt.plot(arima_wcr_train_df.wcr, label='training')\n",
    "plt.plot(arima_wcr_test_df.wcr, label='actual')\n",
    "plt.plot(fc_series, label='forecast')\n",
    "plt.fill_between(lower_series.index, lower_series, upper_series, \n",
    "                 color='k', alpha=.15)\n",
    "plt.title('Forecast vs Actuals')\n",
    "plt.legend(loc='upper left', fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Forecasting with Supervised Learning Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Since time series analysis did not work out as I had hoped, I will try to provide something of value to the company with traditional supervised learning models.\n",
    "\n",
    "In my exploratory analysis, I noted that although a significant number of bookings are made with no lead time or little lead time, about 80% of the bookings were made with a lead time greater than one week. \n",
    "\n",
    "I think that this percentage of bookings with a lead time over a week affords the opportunity to at least forecast final booking amounts with a high degree of accuray for at least one week out. I believe this because I think the data we have is enough to very easily model cancellation rates to a high degree of accuracy. Furthermore I think a one week forecast is enought time to profitably inform business operational and logistic decisions. \n",
    "\n",
    "In order to provide this service, I will first need to be able model booking cancellations.\n",
    "\n",
    "I will do that in this notebook.\n",
    "\n",
    "Below, I will demonstrate that I can predict if an individual booking will be canceled with 91% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### EDA: Multivariate Analysis for Cancellation Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Multivariate Analysis: Data Manipulation\n",
    "\n",
    "Much of the provided data is categorical and cannot be analyzed for correlation in it's current format. However, by calculating a cancellation rate for each value of each categorical variable, we can make some potentially useful features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorical to numerical\n",
    "\n",
    "#Customer\n",
    "\n",
    "#We need to be careful not to scew too much toward cancellation, many customers likely only booked\n",
    "#once and canceled.\n",
    "\n",
    "#For all customer with 2 or more bookings, customer_cancel_score will show the percentage of their bookings that were fulfilled. Customer only one booking. will be given a score of 1.\n",
    "df['customer_cancel_score'] = np.round(np.where(df['is_repeated_guest'] > 0, df['previous_bookings_not_canceled']/(df['previous_bookings_not_canceled'] + df['previous_cancellations']), 0), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Other categorical variables\n",
    "\n",
    "agent_df = pd.DataFrame(df[['is_canceled','agent']].groupby('agent', as_index=False).agg('mean'))\n",
    "agent_df = agent_df.rename(index=str, columns={\"is_canceled\": \"agent_cancel_score\"})\n",
    "df = pd.merge(df,agent_df,how='left',on=['agent'])\n",
    "\n",
    "company_df = pd.DataFrame(df[['is_canceled','company']].groupby('company', as_index=False).agg('mean'))\n",
    "company_df = company_df.rename(index=str, columns={\"is_canceled\": \"company_cancel_score\"})\n",
    "df = pd.merge(df,company_df,how='left',on=['company'])\n",
    "\n",
    "country_df = pd.DataFrame(df[['is_canceled','country']].groupby('country', as_index=False).agg('mean'))\n",
    "country_df = country_df.rename(index=str, columns={\"is_canceled\": \"country_cancel_score\"})\n",
    "df = pd.merge(df,country_df,how='left',on=['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Demonstration:\n",
    "#Let's see what we've made!\n",
    "df[['agent','agent_cancel_score','company','company_cancel_score','country','country_cancel_score']].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#More variables\n",
    "distribution_channel_df = pd.DataFrame(df[['is_canceled','distribution_channel']].groupby('distribution_channel', as_index=False).agg('mean'))\n",
    "distribution_channel_df = distribution_channel_df.rename(index=str, columns={\"is_canceled\": \"distribution_channel_score\"})\n",
    "df = pd.merge(df,distribution_channel_df,how='left',on=['distribution_channel'])\n",
    "\n",
    "market_segment_df = pd.DataFrame(df[['is_canceled','market_segment']].groupby('market_segment', as_index=False).agg('mean'))\n",
    "market_segment_df = market_segment_df.rename(index=str, columns={\"is_canceled\": \"market_segment_score\"})\n",
    "df = pd.merge(df,market_segment_df,how='left',on=['market_segment']) \n",
    "\n",
    "meal_df = pd.DataFrame(df[['is_canceled','meal']].groupby('meal', as_index=False).agg('mean'))\n",
    "meal_df = meal_df.rename(index=str, columns={\"is_canceled\": \"meal_score\"})\n",
    "df = pd.merge(df,meal_df,how='left',on=['meal'])\n",
    "\n",
    "deposit_type_df = pd.DataFrame(df[['is_canceled','deposit_type']].groupby('deposit_type', as_index=False).agg('mean'))\n",
    "deposit_type_df = deposit_type_df.rename(index=str, columns={\"is_canceled\": \"deposit_score\"})\n",
    "df = pd.merge(df,deposit_type_df,how='left',on=['deposit_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Correlation to target: is_cancelled for round one of feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "is_canceled_corr = pd.DataFrame(df.corrwith(df['is_canceled'])).sort_values(by=0, ascending=0)\n",
    "\n",
    "plt.bar(is_canceled_corr.index, height = is_canceled_corr[0])\n",
    "plt.xticks(is_canceled_corr.index, rotation='vertical', fontsize='8')\n",
    "plt.show()\n",
    "\n",
    "print(is_canceled_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Before going on let's analyze this chart:\n",
    "\n",
    "Some of the most highly correlated features are features that were derived from the data\n",
    "manipulation done to get usable data from categorical features.\n",
    "\n",
    "The highest correlated variable are, in order:\n",
    "\n",
    "        LEAD_TIME_SCORE             0.381711\n",
    "        AGENT_CANCEL_SCORE          0.346178\n",
    "        DEPOSIT_SCORE               0.323021\n",
    "        COUNTRY_CANCEL_SCORE        0.302156\n",
    "        MARKET_SEGMENT_SCORE        0.252172\n",
    "    required_car_parking_spaces    -0.243983\n",
    "    lead_time                       0.226453\n",
    "\n",
    "The remaining features are much less correlated to is_cancelled than these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addressing Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since all of the variables we have elected to include are at or above 14% corrrelation to is_cancelled\n",
    "#there is no need to analyze the others for outliers.\n",
    "column_list_one = is_canceled_corr[is_canceled_corr > 0.20].dropna().index\n",
    "column_list_two = is_canceled_corr[is_canceled_corr < -0.20].dropna().index\n",
    "\n",
    "column_list = column_list_one.append(column_list_two)\n",
    "\n",
    "#Non-ratio variables can't have outliers and must be filtered out, we will also filter out the\n",
    "#variables that we don't intend to use because of weak correlation.\n",
    "                 \n",
    "#We'll use the Tukey Interquartile Range method. \n",
    "\n",
    "for i in column_list:\n",
    "    q75, q25 = np.percentile(df[i], [75 ,25])\n",
    "    iqr = q75 - q25\n",
    "    threshold = 2\n",
    "    min_val = q25 - (iqr*threshold)\n",
    "    max_val = q75 + (iqr*threshold)\n",
    "    print(\"The score threshold for \", i, \" is: {}\".format(threshold))\n",
    "    print(\"Number of outliers is: {}\".format(\n",
    "        len((np.where((df[i] > max_val) \n",
    "            | (df[i] < min_val))[0]))\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we have an outlier problem?\n",
    "\n",
    "Of the variables that we may use the following have some outliers at a threshold of 2 IQR:\n",
    "\n",
    "lead_time_score, agent_cancel_score, lead_time, deposit_score, required_car_parking_spaces\n",
    "\n",
    "Deposit_score doesn't really have outliers. As discussed above, there are only 3 different \n",
    "values, each of importance to the model. \n",
    "\n",
    "Lead_time is redundant to lead_time_score\n",
    "\n",
    "This leaves: lead_time_score, agent_cancel_score, lead_time, and required_car_parking_spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Cancel Score\n",
    "\n",
    "Agent cancel score did not have a lot of outliers 202/39956 = 0.5%. Transforming the data to eliminate outliers did not improve correlation.\n",
    "\n",
    "I feel it is best to leave the data as it is, as agents have more and more booking with the hotel, the outliers that are of the most importance would eliminate themseles automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df.agent_cancel_score.describe())\n",
    "\n",
    "print(df.agent_cancel_score.value_counts().head(10))\n",
    "\n",
    "#The average agent cancels about 37% of the time!\n",
    "\n",
    "#There is a small but significant number of agents who cancel more than 70% of the time.\n",
    "#We can't write them out of our analysis.\n",
    "print('corr. w/ no change:', df.is_canceled.corr(df.agent_cancel_score))\n",
    "plt.hist(df.agent_cancel_score)\n",
    "plt.show()\n",
    "\n",
    "#What does it look like transformed?\n",
    "print('corr. w/ sqrt transformation:', df.is_canceled.corr(np.sqrt(df.agent_cancel_score)))\n",
    "plt.hist(np.sqrt(df.agent_cancel_score))\n",
    "plt.show()\n",
    "\n",
    "#What about twice?\n",
    "print('corr. w/ 4thRt transformation:', df.is_canceled.corr(np.sqrt(np.sqrt(df.agent_cancel_score))))\n",
    "plt.hist(np.sqrt(np.sqrt(df.agent_cancel_score)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lead Time\n",
    "\n",
    "Lead time has even fewer outliers than agent_cancel_score, with only 107/39956 or 0.26%.\n",
    "\n",
    "Transforming the data produces a higher correlation though. \n",
    "\n",
    "We can run the model later as it is, or with the transformed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lead time is somewhat correlated and has some outliers at a threshold of 2 IQR.\n",
    "print(df.lead_time.describe())\n",
    "\n",
    "print(df.lead_time.value_counts().head(20))\n",
    "\n",
    "print('corr. w/ no change:', df.is_canceled.corr(df.lead_time))\n",
    "plt.hist(df.lead_time)\n",
    "plt.show()\n",
    "\n",
    "#Not exactly normal, but better.\n",
    "print('corr. w/ no change:', df.is_canceled.corr(np.sqrt(df.lead_time)))\n",
    "plt.hist(np.sqrt(df.lead_time))\n",
    "plt.show()\n",
    "\n",
    "#What about twice?\n",
    "\n",
    "#This one is a much more normal distribution.\n",
    "print('corr. w/ 4thRt transformation:', df.is_canceled.corr(np.sqrt(np.sqrt(df.lead_time))))\n",
    "plt.hist(np.sqrt(np.sqrt(df.lead_time)))\n",
    "plt.show()\n",
    "\n",
    "#Our correlation actually improves with the transformation. We will 4thRt. tranform lead time.\n",
    "df['tf_lead_time'] = np.sqrt(np.sqrt(df.lead_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Car Parking Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required_car_parking_spaces has a few outliers,\n",
    "\n",
    "print(df.required_car_parking_spaces.value_counts())\n",
    "\n",
    "#Anything over one required space is exceedingly rare. Those values be dropped.\n",
    "df = df[df['required_car_parking_spaces']<2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers - Part 2\n",
    "\n",
    "The measures taken above removed all the outliers for lead time, but not much else changed. Outliers don't seem to be a problem with the chosen features though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_canceled_corr = pd.DataFrame(df.corrwith(df['is_canceled'])).sort_values(by=0, ascending=0)\n",
    "\n",
    "plt.bar(is_canceled_corr.index, height = is_canceled_corr[0])\n",
    "plt.xticks(is_canceled_corr.index, rotation='vertical', fontsize='8')\n",
    "plt.show()\n",
    "\n",
    "print(is_canceled_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since all of the variables we have elected to include are at or above 14% corrrelation to is_cancelled\n",
    "#there is no need to analyze the others for outliers.\n",
    "column_list_one = is_canceled_corr[is_canceled_corr > 0.20].dropna().index\n",
    "column_list_two = is_canceled_corr[is_canceled_corr < -0.20].dropna().index\n",
    "\n",
    "column_list = column_list_one.append(column_list_two)\n",
    "\n",
    "#Non-ratio variables can't have outliers and must be filtered out, we will also filter out the\n",
    "#variables that we don't intend to use because of weak correlation.\n",
    "                 \n",
    "#We'll use the Tukey Interquartile Range method. \n",
    "\n",
    "for i in column_list:\n",
    "    q75, q25 = np.percentile(df[i], [75 ,25])\n",
    "    iqr = q75 - q25\n",
    "    threshold = 2\n",
    "    min_val = q25 - (iqr*threshold)\n",
    "    max_val = q75 + (iqr*threshold)\n",
    "    print(\"The score threshold for \", i, \" is: {}\".format(threshold))\n",
    "    print(\"Number of outliers is: {}\".format(\n",
    "        len((np.where((df[i] > max_val) \n",
    "            | (df[i] < min_val))[0]))\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection - Round Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = df[['is_canceled', 'deposit_score', 'agent_cancel_score', 'country_cancel_score', \n",
    "                  'lead_time', 'tf_lead_time', 'market_segment_score', 'required_car_parking_spaces']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collinearity\n",
    "\n",
    "We still need to make a final decision on which lead_time feature to use. There is also some strong correlation between agent_cancel_score and market_segment score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10)) \n",
    "\n",
    "sns.heatmap(features_df.corr())\n",
    "\n",
    "features_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Models\n",
    "\n",
    "The models ran best with the original lead time data, and without counting the interaction between agent and market_segment.\n",
    "\n",
    "The Decision Tree Boosting model had accuracy at 76%, still relatively weak for a class-imbalanced dataset like this one.\n",
    "\n",
    "KNN Nearest Neighboor model produced accuracty between 68.2% and 70.4%\n",
    "\n",
    "Random Forest produced the lowest accuracy at 66%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Evaluation Libraries\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test/Train Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = features_df[features_df['w_date'] <= '2017-05-31']\n",
    "test_df = features_df[features_df['w_date'] > '2017-05-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y is the target variable\n",
    "y_train = train_df['is_canceled']\n",
    "y_test = test_df['is_canceled']\n",
    "\n",
    "# X is the feature set\n",
    "x_train = train_df[['deposit_score', 'agent_cancel_score', 'country_cancel_score', 'market_segment_score', 'required_car_parking_spaces','lead_time']]\n",
    "x_test = test_df[['deposit_score', 'agent_cancel_score', 'country_cancel_score', 'market_segment_score', 'required_car_parking_spaces','lead_time']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Libraries\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = ensemble.RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "#Hyper-parameter tuning\n",
    "param_grid = { \n",
    "    'n_estimators': [200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "rfc = ensemble.RandomForestClassifier(n_estimators=200, max_features='sqrt', max_depth=4, criterion='entropy')\n",
    "\n",
    "rfc.fit(x_train, y_train)\n",
    "\n",
    "y_pred = rfc.predict(x_test)\n",
    "\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    " print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import scipy\n",
    "from sklearn import ensemble\n",
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max Depth 2, default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Store values from loops.\n",
    "preds = pd.DataFrame()\n",
    "labels = []\n",
    "\n",
    "uniquex = df['is_canceled'].unique()\n",
    "\n",
    "for m in range(0, 21):\n",
    "    \n",
    "    # Initialize and fit the tree. Set the max depth to 2.\n",
    "    gradient_boost = ensemble.GradientBoostingClassifier(max_depth=2)\n",
    "    gradient_boost.fit(x_train,y_train)\n",
    "    \n",
    "    # Get and store predicted values.\n",
    "    y_pred = gradient_boost.predict(x_test)\n",
    "    preds['pred{}'.format(m)] = y_pred\n",
    "    \n",
    "    # Residuals.\n",
    "    residuals = y_test - y_pred\n",
    "\n",
    "    # Output every 20 iterations.\n",
    "    if m % 20 == 0:\n",
    "        print('Weak learner {} R^2: {}'.format(m, gradient_boost.score(x_test, y_test)))\n",
    "        labels = labels + [m]\n",
    "        bestpred = preds.sum(axis=1)\n",
    "        plt.plot(uniquex, np.poly1d(np.polyfit(test_df['is_canceled'], bestpred, 1))(uniquex))\n",
    "       \n",
    "plt.legend(labels)\n",
    "plt.xlabel('Original')\n",
    "plt.ylabel('Predicted')\n",
    "plt.show()\n",
    "predicted = preds.sum(axis=1)\n",
    "\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max Depth 8, default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Store values from loops.\n",
    "preds = pd.DataFrame()\n",
    "labels = []\n",
    "\n",
    "uniquex = df['is_canceled'].unique()\n",
    "\n",
    "for m in range(0, 61):\n",
    "    \n",
    "    # Initialize and fit the tree. Set the max depth to 2.\n",
    "    gradient_boost = ensemble.GradientBoostingClassifier(max_depth=8)\n",
    "    gradient_boost.fit(x_train,y_train)\n",
    "    \n",
    "    # Get and store predicted values.\n",
    "    y_pred = gradient_boost.predict(x_test)\n",
    "    preds['pred{}'.format(m)] = y_pred\n",
    "    \n",
    "    # Residuals.\n",
    "    residuals = y_test - y_pred\n",
    "\n",
    "    # Output every 20 iterations.\n",
    "    if m % 20 == 0:\n",
    "        print('Weak learner {} R^2: {}'.format(m, gradient_boost.score(x_test, y_test)))\n",
    "        labels = labels + [m]\n",
    "        bestpred = preds.sum(axis=1)\n",
    "        plt.plot(uniquex, np.poly1d(np.polyfit(test_df['is_canceled'], bestpred, 1))(uniquex))\n",
    "       \n",
    "plt.legend(labels)\n",
    "plt.xlabel('Original')\n",
    "plt.ylabel('Predicted')\n",
    "plt.show()\n",
    "predicted = preds.sum(axis=1)\n",
    "\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Max Depth 8, max_features=sqrt, default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Store values from loops.\n",
    "preds = pd.DataFrame()\n",
    "labels = []\n",
    "\n",
    "uniquex = df['is_canceled'].unique()\n",
    "\n",
    "for m in range(0, 201):\n",
    "    \n",
    "    # Initialize and fit the tree. Set the max depth to 2.\n",
    "    gradient_boost = ensemble.GradientBoostingClassifier(max_depth=8,max_features='sqrt')\n",
    "    gradient_boost.fit(x_train,y_train)\n",
    "    \n",
    "    # Get and store predicted values.\n",
    "    y_pred = gradient_boost.predict(x_test)\n",
    "    preds['pred{}'.format(m)] = y_pred\n",
    "    \n",
    "    # Residuals.\n",
    "    residuals = y_test - y_pred\n",
    "\n",
    "    # Output every 20 iterations.\n",
    "    if m % 20 == 0:\n",
    "        print('Weak learner {} R^2: {}'.format(m, gradient_boost.score(x_test, y_test)))\n",
    "        labels = labels + [m]\n",
    "        bestpred = preds.sum(axis=1)\n",
    "        plt.plot(uniquex, np.poly1d(np.polyfit(test_df['is_canceled'], bestpred, 1))(uniquex))\n",
    "       \n",
    "plt.legend(labels)\n",
    "plt.xlabel('Original')\n",
    "plt.ylabel('Predicted')\n",
    "plt.show()\n",
    "predicted = preds.sum(axis=1)\n",
    "\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    " print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "neighbors.fit(x_train,y_train)\n",
    "\n",
    "knn_results = cross_val_score(neighbors, x_train, y_train, cv=10)\n",
    "\n",
    "y_pred = neighbors.predict(x_test)\n",
    "\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_pred))\n",
    "\n",
    "knn_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = KNeighborsClassifier(n_neighbors=2)\n",
    "\n",
    "neighbors.fit(x_train,y_train)\n",
    "\n",
    "knn_results = cross_val_score(neighbors, x_train, y_train, cv=10)\n",
    "\n",
    "y_pred = neighbors.predict(x_test)\n",
    "\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_pred))\n",
    "\n",
    "knn_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "neighbors.fit(x_train,y_train)\n",
    "\n",
    "knn_results = cross_val_score(neighbors, x_train, y_train, cv=10)\n",
    "\n",
    "y_pred = neighbors.predict(x_test)\n",
    "\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_pred))\n",
    "\n",
    "knn_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = KNeighborsClassifier(n_neighbors=4)\n",
    "\n",
    "neighbors.fit(x_train,y_train)\n",
    "\n",
    "knn_results = cross_val_score(neighbors, x_train, y_train, cv=10)\n",
    "\n",
    "y_pred = neighbors.predict(x_test)\n",
    "\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_pred))\n",
    "\n",
    "knn_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "neighbors = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "neighbors.fit(x_train,y_train)\n",
    "\n",
    "knn_results = cross_val_score(neighbors, x_train, y_train, cv=10)\n",
    "\n",
    "y_pred = neighbors.predict(x_test)\n",
    "\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_pred))\n",
    "\n",
    "knn_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    " print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# One-week forecast with Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have built some intuition about what makes individual bookings more likely to be canceled, maybe I can make a product useful to the company.\n",
    "\n",
    "Many important logistical decisions in a hotel can likely only be made effectively with about a one week notice. Since time series analysis has not done anything to extend that window, perhaps another method can at least improve the quality of decisions withiin that window.\n",
    "\n",
    "Since about 80% of bookings are made with at least one week notice, I may be able to effectively model the cancellation rate for at least the upcoming week. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lbraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#A standardized datetime object will be needed for some analyses\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('processed_hotel_bookings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Aggregation into weekly data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now I need to process the data into weekly aggregates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['w_date'] = df.arrival_date_year.astype(str) + ' ' + df.arrival_date_week_number.astype(str) \n",
    "df['w_date'] = df['w_date'].apply(lambda x: datetime.strptime(x + ' 0', \"%Y %W %w\"))\n",
    "\n",
    "w_deposit_df = pd.DataFrame(df[['deposit_score','w_date']].groupby(['w_date'], as_index=False).agg('mean'))\n",
    "w_deposit_df = w_deposit_df.rename(index=str, columns={\"deposit_score\": \"w_deposit\"})\n",
    "df = pd.merge(df,w_deposit_df,how='left',on='w_date')\n",
    "\n",
    "w_agent_df = pd.DataFrame(df[['agent_cancel_score','w_date']].groupby(['w_date'], as_index=False).agg('mean'))\n",
    "w_agent_df = w_agent_df.rename(index=str, columns={\"agent_cancel_score\": \"w_agent\"})\n",
    "df = pd.merge(df,w_agent_df,how='left',on='w_date')\n",
    "\n",
    "w_country_df = pd.DataFrame(df[['country_cancel_score','w_date']].groupby(['w_date'], as_index=False).agg('mean'))\n",
    "w_country_df = w_country_df.rename(index=str, columns={\"country_cancel_score\": \"w_country\"})\n",
    "df = pd.merge(df,w_country_df,how='left',on='w_date')\n",
    "\n",
    "w_market_df = pd.DataFrame(df[['market_segment_score','w_date']].groupby(['w_date'], as_index=False).agg('mean'))\n",
    "w_market_df = w_market_df.rename(index=str, columns={\"market_segment_score\": \"w_market\"})\n",
    "df = pd.merge(df,w_market_df,how='left',on='w_date')\n",
    "\n",
    "parking_df = pd.DataFrame(df[['required_car_parking_spaces','w_date']].groupby(['w_date'], as_index=False).agg('mean'))\n",
    "parking_df = parking_df.rename(index=str, columns={\"required_car_parking_spaces\": \"w_parking\"})\n",
    "df = pd.merge(df,parking_df,how='left',on='w_date')\n",
    "\n",
    "w_lead_time_df = pd.DataFrame(df[['lead_time','w_date']].groupby(['w_date'], as_index=False).agg('mean'))\n",
    "w_lead_time_df = w_lead_time_df.rename(index=str, columns={\"lead_time\": \"w_lead_time\"})\n",
    "df = pd.merge(df,w_lead_time_df,how='left',on='w_date')\n",
    "\n",
    "canceled_df = pd.DataFrame(df[['is_canceled','w_date']].groupby(['w_date'], as_index=False).agg('mean'))\n",
    "canceled_df = canceled_df.rename(index=str, columns={\"is_canceled\": \"w_canceled\"})\n",
    "df = pd.merge(df,canceled_df,how='left',on='w_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = df[['w_canceled','w_deposit','w_agent','w_country','w_market','w_parking','w_lead_time','w_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = features_df.drop_duplicates()\n",
    "features_df = features_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = features_df.drop(columns={'index'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Evaluation Libraries\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test/Train Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = features_df[features_df['w_date'] <= '2017-05-31']\n",
    "test_df = features_df[features_df['w_date'] > '2017-05-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y is the target variable\n",
    "y_train = train_df['w_canceled']\n",
    "y_test = test_df['w_canceled']\n",
    "\n",
    "# X is the feature set\n",
    "x_train = train_df[['w_deposit','w_agent','w_country','w_market','w_parking','w_lead_time']]\n",
    "x_test = test_df[['w_deposit','w_agent','w_country','w_market','w_parking','w_lead_time']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Libraries\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = ensemble.RandomForestRegressor(n_jobs=-1)\n",
    "\n",
    "#Hyper-parameter tuning\n",
    "param_grid = { \n",
    "    'n_estimators': [200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['mse', 'mae']\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "rfc = ensemble.RandomForestRegressor(n_estimators=200, max_features='auto', max_depth=6, criterion='mae')\n",
    "\n",
    "rfc.fit(x_train, y_train)\n",
    "\n",
    "y_pred = rfc.predict(x_test)\n",
    "\n",
    "cxval = cross_val_score(rfc, x_test, y_test, cv=5)\n",
    "\n",
    "print(cxval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are so bad that no hyperparameter tuning will salvage them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import scipy\n",
    "from sklearn import ensemble\n",
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Max Depth 2, default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Store values from loops.\n",
    "preds = pd.DataFrame()\n",
    "labels = []\n",
    "\n",
    "uniquex = df['w_canceled'].unique()\n",
    "\n",
    "for m in range(0, 21):\n",
    "    \n",
    "    # Initialize and fit the tree. Set the max depth to 2.\n",
    "    gradient_boost = ensemble.GradientBoostingRegressor(max_depth=2)\n",
    "    gradient_boost.fit(x_train,y_train)\n",
    "    \n",
    "    # Get and store predicted values.\n",
    "    y_pred = gradient_boost.predict(x_test)\n",
    "    preds['pred{}'.format(m)] = y_pred\n",
    "    \n",
    "    # Residuals.\n",
    "    residuals = y_test - y_pred\n",
    "\n",
    "    # Output every 20 iterations.\n",
    "    if m % 20 == 0:\n",
    "        print('Weak learner {} R^2: {}'.format(m, gradient_boost.score(x_test, y_test)))\n",
    "        labels = labels + [m]\n",
    "        bestpred = preds.sum(axis=1)\n",
    "        plt.plot(uniquex, np.poly1d(np.polyfit(test_df['w_canceled'], bestpred, 1))(uniquex))\n",
    "       \n",
    "plt.legend(labels)\n",
    "plt.xlabel('Original')\n",
    "plt.ylabel('Predicted')\n",
    "plt.show()\n",
    "predicted = preds.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Review and Further Research Proposed:\n",
    "\n",
    "The data did not really lend itself to classical ARIMA modeling. The data is noisy and seasonal. An acceptable trend line was produced, that could perhaps be used as a general baseline for planning. However, an analysis of the residuals makes it clear that there is much left to be desired. Perhaps analysis with a more sophisticated TSA model such as SES or SARIMA would produce something of real value.\n",
    "\n",
    "The random forest model shows promise, but has limitations.\n",
    "\n",
    "The random forest model produced a remarkably low mean negative absolute error. And over half of the predictions had less than a 1% residual.\n",
    "\n",
    "However, it can only be used one week in advanace. Even though the average cancellation rate of bookings made less than one week in advance in known, it too can fluctuate significantly. Futhermore the model depends on a separate estimate of gross booking dmeand to be useful. \n",
    "\n",
    "With only 26 months of data, it should have been expected that forecasting would be hard, especially since ARIMA is not meant for seasonal data, and this data is somewhat seasonal. \n",
    "\n",
    "To improve results I recommend the following:\n",
    "\n",
    "1. If data over a longer time period is available it should be used.\n",
    "\n",
    "2. A more sophisticated model such as SARIMA should be used to difference the data seassonally and hopefully achieve a better forecasting result. \n",
    "\n",
    "3. The data offeres many opportunities to be explored at a more micro-scale. Models could be built for individual countries, agents, marketing channels, compnanies and more. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
